{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import nltk\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"Machine Learning/Models/Model_v1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/weihern/Documents/Computing Projects/FRIDAY/context.txt') as f:\n",
    "    context = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(sentence):\n",
    "    return len(nltk.word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = []\n",
    "MAX_LENGTH = 120\n",
    "curr_count = 0\n",
    "chunk = []\n",
    "for sentence in sentences:\n",
    "    word_c = word_count(sentence)\n",
    "    if curr_count + word_c < MAX_LENGTH:\n",
    "        chunk.append(sentence)\n",
    "        curr_count += word_c\n",
    "    else:\n",
    "        chunk.append(sentence)\n",
    "        curr_count = 0\n",
    "        chunks.append(' '.join(chunk))\n",
    "        chunk = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "for i,chunk in enumerate(chunks):\n",
    "    embeddings = model.encode(chunk)\n",
    "    mapping[i] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What SD card do i use?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_embedding = model.encode(query)\n",
    "HIGHEST = 0\n",
    "index = -1\n",
    "for k,v in mapping.items():\n",
    "    dot_product = np.dot(q_embedding, v)\n",
    "    if dot_product > HIGHEST:\n",
    "        HIGHEST = dot_product\n",
    "        index = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kind Reminder: 1. Please use 16gb-32gb micro sd card, class 10 or above(SD card is not included). We recommend to use Samsung or Sandisk sd card. Please format the sd card on computer and on camera first before recording. 2. Please turn off motion detection function and reduce G-sensor sensitivity when you are driving. 3. Please press the OK button to pause the recording first, then press the MENU button to access the setting. 4. The dashboard camera is equipped with a small battery for saving emergency file and setting only. The dash cam will shut down after 5mins if there is no extenral power connection.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/weihern/Documents/Computing Projects/FRIDAY/Machine Learning/Notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a82152883a9ae0824417df8eee29fc768be135be911d7c9b59fdda4f963266b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
