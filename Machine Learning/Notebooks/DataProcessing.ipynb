{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8_5jDYNbrzSN"
      },
      "source": [
        "### Exploratory Data Analysis \n",
        "This notebook contains code that explores the [Amazon Reviews Dataset](https://jmcauley.ucsd.edu/data/amazon_v2/index.html).\n",
        "\n",
        "This notebook implements various functions to load the training, testing and validation data from the [Amazon Questions and Answers Dataset](https://github.com/amazonqa/amazonqa) without having to load the entire dataset into memory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PcpubL-z5Bh",
        "outputId": "a070ee88-dd1f-4978-c590-9a1eadd35761"
      },
      "outputs": [],
      "source": [
        "# !pip install -U sentence-transformers\n",
        "# !pip install transformers\n",
        "# !pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FUzYdAjFrzSP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import gzip\n",
        "import json\n",
        "import requests\n",
        "from io import BytesIO, StringIO\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import ssl\n",
        "import os\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vhlxb3OsnN9G"
      },
      "outputs": [],
      "source": [
        "# _ = urllib.request.urlretrieve(\"https://amazon-qa.s3-us-west-2.amazonaws.com/train-qar.jsonl\", \"../Data/train-qar.jsonl\")\n",
        "# _ = urllib.request.urlretrieve(\"https://amazon-qa.s3-us-west-2.amazonaws.com/val-qar.jsonl\", \"../Data/var-qar.jsonl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2Oc9RGgRl-6I"
      },
      "outputs": [],
      "source": [
        "def get_data(url,N,downloaded):\n",
        "  '''\n",
        "  Args: \n",
        "    url: url of the data\n",
        "    N: number of rows to be returned\n",
        "    downloaded: True if the data is already downloaded\n",
        "\n",
        "  Returns a dataframe of N rows such that not all the data is loaded into memory\n",
        "  '''\n",
        "\n",
        "  im_path = \"../Data/\" + url.split('/')[-1]\n",
        "  final_path = im_path.replace('.gz','')\n",
        "  if not downloaded:\n",
        "    _ = urllib.request.urlretrieve(url, im_path)\n",
        "    with gzip.open(im_path, 'rb') as infile:\n",
        "      with open(final_path, 'wb') as outfile:\n",
        "          for line in infile:\n",
        "              outfile.write(line)\n",
        "  it = pd.read_json(final_path,chunksize = 1000,lines= True)\n",
        "  first_n_rows = pd.DataFrame()\n",
        "  for chunk in it:\n",
        "      first_n_rows = pd.concat([first_n_rows,chunk.head(N)])\n",
        "      if len(first_n_rows) >= N:\n",
        "          break\n",
        "  return first_n_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xo181g2CnFRC"
      },
      "outputs": [],
      "source": [
        "desc = get_data('https://jmcauley.ucsd.edu/data/amazon_v2/metaFiles2/meta_Toys_and_Games.json.gz',500000,True) #first 500000 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CSblCvEurzSQ"
      },
      "outputs": [],
      "source": [
        "desc['description'] = desc['description'].apply(lambda item: ' '.join([y for y in ''.join(item).split('<') if '>' not in y]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4EoOXGZWrzSQ"
      },
      "outputs": [],
      "source": [
        "df_desc = desc[['title','asin', 'description']].drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "A_MM0MUlrzSQ"
      },
      "outputs": [],
      "source": [
        "df_ids = desc['asin'].unique().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done with 738776 records from: ../Data/train-qar.jsonl\n",
            "Done with 92183 records from: ../Data/var-qar.jsonl\n",
            "Done with 92726 records from: ../Data/test-qar_all.jsonl\n"
          ]
        }
      ],
      "source": [
        "def parse_jsonl_all(path,savepath):\n",
        "  '''\n",
        "  Args:\n",
        "    path: path to the jsonl file\n",
        "\n",
        "  The function is written to handle the csv in chunks of N rows\n",
        "  Returns a csv file with all the data in the jsonl file\n",
        "  '''\n",
        "\n",
        "\n",
        "  N = 10000 #chunksize\n",
        "  L = 0\n",
        "  counter = 0\n",
        "  dfs = []\n",
        "  with open(path) as f:\n",
        "    for i, line in enumerate(f):\n",
        "      print('Parsing:', i, '            ',end='\\r')\n",
        "      try:\n",
        "        dfs.append(pd.json_normalize(json.loads(line)))\n",
        "        counter += 1\n",
        "        L += 1\n",
        "        if counter > N:\n",
        "          df = pd.concat(dfs)\n",
        "          dfs = []\n",
        "          counter = 0\n",
        "          if os.path.exists(savepath):\n",
        "            df.to_csv(savepath,header=False,index=False,mode='a')\n",
        "          else:\n",
        "            df.to_csv(savepath,header=True,index=False)\n",
        "      except:\n",
        "        pass\n",
        "  print('Done with',L, 'records from:', path)\n",
        "  return \n",
        "parse_jsonl_all('../Data/train-qar.jsonl','../Data/train_processed.csv')\n",
        "parse_jsonl_all('../Data/var-qar.jsonl','../Data/var_processed.csv')\n",
        "parse_jsonl_all('../Data/test-qar_all.jsonl','../Data/test_processed.csv')\n",
        "# from google.colab import files\n",
        "# files.download('all_processed.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15 (main, Nov 24 2022, 08:29:02) \n[Clang 14.0.6 ]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6a82152883a9ae0824417df8eee29fc768be135be911d7c9b59fdda4f963266b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
